{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/torch-2.4/repo.html\n",
      "Requirement already satisfied: dgl in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from dgl) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from dgl) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.1 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from dgl) (3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from dgl) (4.66.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from dgl) (5.9.0)\n",
      "Collecting torchdata>=0.5.0 (from dgl)\n",
      "  Using cached torchdata-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting pandas (from dgl)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
      "Collecting torch>=2 (from torchdata>=0.5.0->dgl)\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from pandas->dgl) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas->dgl)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->dgl)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from tqdm->dgl) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
      "Collecting filelock (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n",
      "Collecting jinja2 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mekhani\\anaconda3\\envs\\dglenv\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torchdata-0.9.0-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 33.3 kB/s eta 0:00:00\n",
      "Installing collected packages: pytz, mpmath, tzdata, sympy, MarkupSafe, fsspec, filelock, pandas, jinja2, torch, torchdata\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.10.0 jinja2-3.1.4 mpmath-1.3.0 pandas-2.2.3 pytz-2024.2 sympy-1.13.1 torch-2.5.1 torchdata-0.9.0 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot find DGL C++ graphbolt library at c:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\graphbolt\\graphbolt_pytorch_2.5.1.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGLBACKEND\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphbolt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\__init__.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_verbose_logging  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_name, load_backend  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     container,\n\u001b[0;32m     18\u001b[0m     cuda,\n\u001b[0;32m     19\u001b[0m     dataloading,\n\u001b[0;32m     20\u001b[0m     function,\n\u001b[0;32m     21\u001b[0m     ops,\n\u001b[0;32m     22\u001b[0m     random,\n\u001b[0;32m     23\u001b[0m     sampling,\n\u001b[0;32m     24\u001b[0m     storages,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, DGLError\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     extract_ext_funcs,\n\u001b[0;32m     29\u001b[0m     get_global_func,\n\u001b[0;32m     30\u001b[0m     list_global_func_names,\n\u001b[0;32m     31\u001b[0m     register_func,\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\dataloading\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mget_preferred_backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspot_target\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_dataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\dataloading\\dataloader.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m batch \u001b[38;5;28;01mas\u001b[39;00m batch_graphs\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPUCache\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistGraph\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyFeature\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheterograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DGLGraph\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\distributed\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exit_client, initialize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_dataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistDataLoader\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistGraph, DistGraphServer, edge_split, node_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistTensor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_partition_book\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphPartitionBook, PartitionPolicy\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\distributed\\dist_graph.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MutableMapping\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m F, graphbolt \u001b[38;5;28;01mas\u001b[39;00m gb, heterograph_index\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m empty_shared_mem\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL, DGLError, EID, ETYPE, is_all, NID\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\graphbolt\\__init__.py:36\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=W0703\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load Graphbolt C++ library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mload_graphbolt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# pylint: disable=wrong-import-position\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\graphbolt\\__init__.py:26\u001b[0m, in \u001b[0;36mload_graphbolt\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, basename)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find DGL C++ graphbolt library at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Cannot find DGL C++ graphbolt library at c:\\Users\\MEKhani\\anaconda3\\envs\\dglenv\\Lib\\site-packages\\dgl\\graphbolt\\graphbolt_pytorch_2.5.1.dll"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.graphbolt as gb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is already preprocessed.\n"
     ]
    }
   ],
   "source": [
    "dataset = gb.BuiltinDataset(\"ogbn-arxiv\",root=\"../../../data/datasets\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset consists of graph, feature and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: node_classification. Number of classes: 40\n"
     ]
    }
   ],
   "source": [
    "graph = dataset.graph\n",
    "feature = dataset.feature\n",
    "train_set = dataset.tasks[0].train_set\n",
    "valid_set = dataset.tasks[0].validation_set\n",
    "test_set = dataset.tasks[0].test_set\n",
    "task_name = dataset.tasks[0].metadata[\"name\"]\n",
    "num_classes = dataset.tasks[0].metadata[\"num_classes\"]\n",
    "print(f\"Task: {task_name}. Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Neighbor Sampler and Data Loader in DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = gb.ItemSampler(train_set, batch_size=1024, shuffle=True)\n",
    "datapipe = datapipe.sample_neighbor(graph, [4, 4])\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
    "datapipe = datapipe.copy_to(device)\n",
    "train_dataloader = gb.DataLoader(datapipe, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate over the data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatch(seeds=tensor([ 58827, 158930,  33891,  ...,  40174,  87576, 101915]),\n",
      "          sampled_subgraphs=[SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([    0,     4,     7,  ..., 14817, 14819, 14823], dtype=torch.int32),\n",
      "                                                                         indices=tensor([ 3886,  1026,  3593,  ...,  3527,  5759, 11912], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([ 58827, 158930,  33891,  ..., 124995, 109848, 145819]),\n",
      "                                               original_edge_ids=tensor([ 964979, 1482575, 2079753,  ...,  816651, 1765725, 1999714]),\n",
      "                                               original_column_node_ids=tensor([ 58827, 158930,  33891,  ..., 103509,  28854,  18145]),\n",
      "                            ),\n",
      "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    4,    7,  ..., 3671, 3674, 3677], dtype=torch.int32),\n",
      "                                                                         indices=tensor([1024, 1025, 1026,  ..., 3885, 3309, 1023], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([ 58827, 158930,  33891,  ..., 103509,  28854,  18145]),\n",
      "                                               original_edge_ids=tensor([1900196,  613420, 1482575,  ...,  247507, 1340531, 2417513]),\n",
      "                                               original_column_node_ids=tensor([ 58827, 158930,  33891,  ...,  40174,  87576, 101915]),\n",
      "                            )],\n",
      "          node_features={'feat': tensor([[-0.1230,  0.0471, -0.1980,  ...,  0.1179, -0.0016, -0.0741],\n",
      "                                [-0.0409, -0.1553,  0.0286,  ...,  0.2027,  0.0610, -0.1968],\n",
      "                                [ 0.0340,  0.0931, -0.1600,  ...,  0.1183, -0.0735, -0.2682],\n",
      "                                ...,\n",
      "                                [-0.0666, -0.0415, -0.2445,  ...,  0.2223,  0.1201, -0.1959],\n",
      "                                [-0.1804, -0.2674, -0.2395,  ...,  0.1594, -0.1932, -0.2405],\n",
      "                                [-0.1003, -0.3591, -0.1804,  ...,  0.1736,  0.0235,  0.1958]])},\n",
      "          labels=tensor([27,  2, 28,  ..., 27, 36, 36]),\n",
      "          input_nodes=tensor([ 58827, 158930,  33891,  ..., 124995, 109848, 145819]),\n",
      "          indexes=None,\n",
      "          edge_features=[{},\n",
      "                        {}],\n",
      "          compacted_seeds=None,\n",
      "          blocks=[Block(num_src_nodes=11913, num_dst_nodes=3886, num_edges=14823),\n",
      "                 Block(num_src_nodes=3886, num_dst_nodes=1024, num_edges=3677)],\n",
      "       )\n",
      "hello to new envirement \n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "print(data)\n",
    "print(\"hello to new envirement \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " node IDs from MFGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input nodes tensor([ 58827, 158930,  33891,  ..., 124995, 109848, 145819]). \n"
     ]
    }
   ],
   "source": [
    "mfgs =data.blocks\n",
    "input_nodes = mfgs[0].srcdata[dgl.NID]\n",
    "print(f\"Input nodes {input_nodes }. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self ,in_feat,h_feat,num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_feat,h_feat,aggregator_type=\"mean\")\n",
    "        self.conv2 = SAGEConv(h_feat,num_classes,aggregator_type=\"mean\")\n",
    "        self.h_feat = h_feat \n",
    "    def forward(self ,mfgs,x):\n",
    "        h= self.conv1(mfgs[0],x)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(mfgs[1],h)\n",
    "        return h \n",
    "in_size = feature.size(\"node\", None, \"feat\")[0]\n",
    "model = myModel(in_size,16,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define valdiation loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = gb.ItemSampler(valid_set, batch_size=1024, shuffle=True)\n",
    "datapipe = datapipe.sample_neighbor(graph, [4, 4])\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
    "datapipe = datapipe.copy_to(device)\n",
    "valid_dataloader = gb.DataLoader(datapipe, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:02, 33.41it/s, loss=2.858, acc=0.267]\n",
      "30it [00:00, 48.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation Accuracy 0.3102117520722172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step , data in enumerate(tq):\n",
    "            x = data.node_features[\"feat\"]\n",
    "            labels = data.labels\n",
    "\n",
    "            predictions= model(data.blocks,x)\n",
    "\n",
    "            loss = F.cross_entropy(predictions,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = sklearn.metrics.accuracy_score(\n",
    "                labels.cpu().numpy(),predictions.argmax(1).detach().cpu().numpy()\n",
    "            )\n",
    "            tq.set_postfix(\n",
    "                 {\"loss\": \"%.03f\" % loss.item(), \"acc\": \"%.03f\" % accuracy},\n",
    "                refresh=False,\n",
    "            )\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with tqdm.tqdm(valid_dataloader) as tq:\n",
    "        for step , data in enumerate(tq):\n",
    "            x = data.node_features[\"feat\"]\n",
    "            labels.append(data.labels.cpu().numpy())\n",
    "            predictions.append(model(data.blocks, x).argmax(1).cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        print(\"Epoch {} Validation Accuracy {}\".format(epoch, accuracy))\n",
    "\n",
    "        # Note that this tutorial do not train the whole model to the end.\n",
    "    \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dglenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
