{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl==0.4.2Note: you may need to restart the kernel to use updated packages.\n",
      "  Downloading dgl-0.4.2-cp36-cp36m-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\mekhani\\anaconda3\\envs\\torch_env\\lib\\site-packages (from dgl==0.4.2) (1.19.2)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting networkx>=2.1\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting decorator<5,>=4.3\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: decorator, scipy, networkx, dgl\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 dgl-0.4.2 networkx-2.5.1 scipy-1.5.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install dgl==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "\n",
    "# Install the CPU version. If you want to install CUDA version, please\n",
    "# refer to https://www.dgl.ai/pages/start.html.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import dgl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 0, 0, 0, 0]), tensor([1, 2, 3, 4, 5]))\n",
      "tensor([[ 0.6380, -1.2825, -0.5653,  1.6395],\n",
      "        [ 0.7730, -0.7976, -2.2126,  0.8768],\n",
      "        [-1.4070, -0.2499,  0.9860,  1.1545],\n",
      "        [-1.1851, -0.0031,  0.1843,  2.1588],\n",
      "        [-0.1960, -0.2439, -0.5612,  2.6180]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]), num_nodes=6)\n",
    "# Equivalently, PyTorch LongTensors also work.\n",
    "g = dgl.graph(\n",
    "    (torch.LongTensor([0, 0, 0, 0, 0]), torch.LongTensor([1, 2, 3, 4, 5])),\n",
    "    num_nodes=6,\n",
    ")\n",
    "\n",
    "# You can omit the number of nodes argument if you can tell the number of nodes from the edge list alone.\n",
    "g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]))\n",
    "print(g.edges())\n",
    "# Assign a 3-dimensional node feature vector for each node.\n",
    "g.ndata[\"x\"] = torch.randn(6, 3)\n",
    "# Assign a 4-dimensional edge feature vector for each edge.\n",
    "g.edata[\"a\"] = torch.randn(5, 4)\n",
    "# Assign a 5x4 node feature matrix for each node.  Node and edge features in DGL can be multi-dimensional.\n",
    "g.ndata[\"y\"] = torch.randn(6, 5, 4)\n",
    "\n",
    "print(g.edata[\"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is already preprocessed.\n"
     ]
    }
   ],
   "source": [
    "dataset = gb.BuiltinDataset(\"cora-seeds\",root=\"../../../data/datasets\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: link_prediction.\n"
     ]
    }
   ],
   "source": [
    "graph = dataset.graph\n",
    "feature = dataset.feature\n",
    "train_set = dataset.tasks[1].train_set\n",
    "test_set = dataset.tasks[1].test_set\n",
    "task_name = dataset.tasks[1].metadata[\"name\"]\n",
    "print(f\"Task: {task_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "datapipe = gb.ItemSampler(train_set, batch_size=256, shuffle=True)\n",
    "datapipe = datapipe.sample_uniform_negative(graph, 5)\n",
    "datapipe = datapipe.sample_neighbor(graph, [5, 5, 5])\n",
    "datapipe = datapipe.transform(partial(gb.exclude_seed_edges, include_reverse_edges=True))\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
    "datapipe = datapipe.copy_to(device)\n",
    "train_dataloader = gb.DataLoader(datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatch: MiniBatch(seeds=tensor([[2352, 1129],\n",
      "                        [ 893, 2383],\n",
      "                        [1303,  979],\n",
      "                        ...,\n",
      "                        [ 132,   20],\n",
      "                        [ 132, 2046],\n",
      "                        [ 132,   46]], dtype=torch.int32),\n",
      "          sampled_subgraphs=[SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    2,    6,  ..., 7663, 7664, 7666], dtype=torch.int32),\n",
      "                                                                         indices=tensor([ 144,  931,  144,  ..., 2228, 2250, 2252], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([2352, 1129,  893,  ..., 2342,  594,  663], dtype=torch.int32),\n",
      "                                               original_edge_ids=None,\n",
      "                                               original_column_node_ids=tensor([2352, 1129,  893,  ..., 2337, 2421, 2661], dtype=torch.int32),\n",
      "                            ),\n",
      "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    2,    6,  ..., 6991, 6996, 6997], dtype=torch.int32),\n",
      "                                                                         indices=tensor([ 144,  931,  144,  ..., 2175, 2371, 1287], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([2352, 1129,  893,  ..., 2337, 2421, 2661], dtype=torch.int32),\n",
      "                                               original_edge_ids=None,\n",
      "                                               original_column_node_ids=tensor([2352, 1129,  893,  ..., 2254, 2018, 1407], dtype=torch.int32),\n",
      "                            ),\n",
      "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    2,    6,  ..., 3795, 3800, 3802], dtype=torch.int32),\n",
      "                                                                         indices=tensor([ 144,  931,  144,  ..., 1199, 2226, 2071], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([2352, 1129,  893,  ..., 2254, 2018, 1407], dtype=torch.int32),\n",
      "                                               original_edge_ids=None,\n",
      "                                               original_column_node_ids=tensor([2352, 1129,  893,  ..., 2449, 2046,   46], dtype=torch.int32),\n",
      "                            )],\n",
      "          node_features={'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                ...,\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.]])},\n",
      "          labels=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
      "          input_nodes=tensor([2352, 1129,  893,  ..., 2342,  594,  663], dtype=torch.int32),\n",
      "          indexes=tensor([  0,   1,   2,  ..., 255, 255, 255]),\n",
      "          edge_features=[{},\n",
      "                        {},\n",
      "                        {}],\n",
      "          compacted_seeds=tensor([[   0,    1],\n",
      "                                  [   2,    3],\n",
      "                                  [   4,    5],\n",
      "                                  ...,\n",
      "                                  [ 423,  757],\n",
      "                                  [ 423, 1289],\n",
      "                                  [ 423, 1290]], dtype=torch.int32),\n",
      "          blocks=[Block(num_src_nodes=2603, num_dst_nodes=2530, num_edges=7666),\n",
      "                 Block(num_src_nodes=2530, num_dst_nodes=2259, num_edges=6997),\n",
      "                 Block(num_src_nodes=2259, num_dst_nodes=1291, num_edges=3802)],\n",
      "       )\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "print(f\"MiniBatch: {data}\")\n",
    "# data.node_pairs_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model for Node Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dglnn.SAGEConv(in_size, hidden_size, \"mean\"))\n",
    "        self.layers.append(dglnn.SAGEConv(hidden_size, hidden_size, \"mean\"))\n",
    "        self.hidden_size = hidden_size\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, blocks, x):\n",
    "        hidden_x = x\n",
    "        \n",
    "        for layer_idx, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
    "            hidden_x = layer(block, hidden_x)\n",
    "            is_last_layer = layer_idx == len(self.layers) - 1\n",
    "            if not is_last_layer:\n",
    "                hidden_x = F.relu(hidden_x)\n",
    "        return hidden_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initilize `model` and define `optimizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = feature.size(\"node\",None,\"feat\")[0]\n",
    "model = SAGE(in_size,128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainig loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93cecc2a75943188258200de7fced88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss 0.571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd63dfda29284915ab571d6437a35bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss 0.450\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, data in tqdm(enumerate(train_dataloader)):\n",
    "        # Get node pairs with labels for loss calculation.\n",
    "        compacted_seeds = data.compacted_seeds.T\n",
    "        labels = data.labels\n",
    "        node_feature = data.node_features[\"feat\"]\n",
    "        # Convert sampled subgraphs to DGL blocks.\n",
    "        blocks = data.blocks\n",
    "\n",
    "        # Get the embeddings of the input nodes.\n",
    "        y = model(blocks, node_feature)\n",
    "        logits = model.predictor(\n",
    "            y[compacted_seeds[0]] * y[compacted_seeds[1]]\n",
    "        ).squeeze()\n",
    "\n",
    "        # Compute loss.\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss {total_loss / (step + 1):.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dab1aa4c3a43e4bef9eedcd827e266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link Prediction AUC: 0.7427011971878439\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "datapipe = gb.ItemSampler(test_set, batch_size=256, shuffle=False)\n",
    "datapipe = datapipe.copy_to(device)\n",
    "# Since we need to use all neghborhoods for evaluation, we set the fanout\n",
    "# to -1.\n",
    "datapipe = datapipe.sample_neighbor(graph, [-1, -1])\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
    "eval_dataloader = gb.DataLoader(datapipe, num_workers=0)\n",
    "\n",
    "logits = []\n",
    "labels = []\n",
    "for step, data in tqdm(enumerate(eval_dataloader)):\n",
    "    # Get node pairs with labels for loss calculation.\n",
    "    compacted_seeds = data.compacted_seeds.T\n",
    "    label = data.labels\n",
    "\n",
    "    # The features of sampled nodes.\n",
    "    x = data.node_features[\"feat\"]\n",
    "\n",
    "    # Forward.\n",
    "    y = model(data.blocks, x)\n",
    "    logit = (\n",
    "        model.predictor(y[compacted_seeds[0]] * y[compacted_seeds[1]])\n",
    "        .squeeze()\n",
    "        .detach()\n",
    "    )\n",
    "\n",
    "    logits.append(logit)\n",
    "    labels.append(label)\n",
    "\n",
    "logits = torch.cat(logits, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "\n",
    "\n",
    "# Compute the AUROC score.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(labels.cpu(), logits.cpu())\n",
    "print(\"Link Prediction AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "14\n",
      "1\n",
      "7\n",
      "21\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x= [1,2,3]\n",
    "y=[7,7,7,7,7,7,7,7,7,7,77,7,7,7]\n",
    "for index, (y1,x1) in enumerate(zip(x, y)):\n",
    "    print(x1)\n",
    "    print(x1*y1)\n",
    "    print(index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
